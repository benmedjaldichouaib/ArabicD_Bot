import re
import pandas as pd
import google.generativeai as genai
from camel_tools.utils.dediac import dediac_ar
from gtts import gTTS
from telegram import Update, InputFile
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes, MessageHandler, filters
import os

# -------------------- CONFIGURATION --------------------
TOKEN = os.environ.get("TOKEN")
GENIE_API_KEY = os.environ.get("GENIE_API_KEY")
CSV_FILE = "sorted_cefr.csv"  # Upload this CSV to your GitHub repo

genai.configure(api_key=GENIE_API_KEY)

# -------------------- LOAD CSV --------------------
df = pd.read_csv(CSV_FILE)
df.columns = df.columns.str.strip()

# -------------------- REGEX --------------------
ARABIC_REGEX = re.compile(r'^[\u0600-\u06FF]+$')

# -------------------- FUNCTIONS --------------------
def speak(word, filename="word_output.mp3"):
    tts = gTTS(word, lang="ar")
    tts.save(filename)
    return filename

def normalize_arabic_word(word):
    return dediac_ar(word).lstrip("Ø§Ù„")

def normalize_with_gemini(word):
    prompt = f"""
    Ø§Ù„ÙƒÙ„Ù…Ø©: "{word}"
    Ù‡Ù„ Ø§Ù„ÙƒÙ„Ù…Ø© Ù…Ø¹Ø±ÙØ© Ø¨Ù€ "Ø§Ù„" Ø£Ùˆ Ø¬Ù…Ø¹ØŸ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ÙƒØ°Ù„ÙƒØŒ Ø£Ø¹Ø·Ù†ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ø¨ØµÙŠØºØªÙ‡Ø§ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø£Ùˆ Ø§Ù„Ù…ÙØ±Ø¯Ø© ÙÙ‚Ø·.
    """
    model = genai.GenerativeModel("gemini-2.5-flash")
    response = model.generate_content(prompt)
    return response.text.strip().split()[0] if response.text else word

def get_gemini_completion(word):
    prompt = f"""
    Ø£Ø¹Ø·Ù†ÙŠ ØªØ­Ù„ÙŠÙ„Ù‹Ø§ Ø¯Ù‚ÙŠÙ‚Ù‹Ø§ Ù„Ù„ÙƒÙ„Ù…Ø© "{word}" Ø¨ØµÙŠØºØ© ÙˆØ§Ø¶Ø­Ø©:
    ÙƒÙ„Ù…Ø©: {word}
    Ù…Ø³ØªÙˆÙ‰ CEFR:
    Ø§Ù„Ù…Ø¬Ø§Ù„:
    Ù†ÙˆØ¹ Ø§Ù„ÙƒÙ„Ù…Ø©:
    Ø§Ù„Ø¬Ø°Ø±:
    Ø§Ù„ØªØ¹Ø±ÙŠÙ:
    Ø§Ù„Ù…Ø±Ø§Ø¯ÙØ§Øª:
    Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯:
    Ù…Ø«Ø§Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…:
    Ø§Ù„Ø³ÙŠØ§Ù‚:
    """
    model = genai.GenerativeModel("gemini-2.0-flash")
    response = model.generate_content(prompt)
    return response.text.strip() if response.text else "ØºÙŠØ± Ù…ØªÙˆÙØ±"

def fetch_word_data(word):
    global df
    base_word = normalize_with_gemini(word)
    normalized_word = normalize_arabic_word(base_word)
    result = df[df["Word"] == normalized_word]

    data = {}
    if not result.empty:
        data.update(result.iloc[0].to_dict())
    else:
        generated_text = get_gemini_completion(normalized_word)
        fields = {
            "CEFR Level": "Ù…Ø³ØªÙˆÙ‰ CEFR",
            "Field": "Ø§Ù„Ù…Ø¬Ø§Ù„",
            "Part of Speech": "Ù†ÙˆØ¹ Ø§Ù„ÙƒÙ„Ù…Ø©",
            "Lemma": "Ø§Ù„Ø¬Ø°Ø±",
            "Definition": "Ø§Ù„ØªØ¹Ø±ÙŠÙ",
            "Synonyms": "Ø§Ù„Ù…Ø±Ø§Ø¯ÙØ§Øª",
            "Antonyms": "Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯",
            "Phrase Example": "Ù…Ø«Ø§Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…",
            "Ø§Ù„Ø³ÙŠØ§Ù‚": "Ø§Ù„Ø³ÙŠØ§Ù‚"
        }
        data["Word"] = normalized_word
        for field, label in fields.items():
            for line in generated_text.split("\n"):
                if line.startswith(label):
                    data[field] = line.split(": ", 1)[1] if ": " in line else "ØºÙŠØ± Ù…ØªÙˆÙØ±"
                    break
            else:
                data[field] = "ØºÙŠØ± Ù…ØªÙˆÙØ±"
        df = pd.concat([df, pd.DataFrame([data])], ignore_index=True)
        df.to_csv(CSV_FILE, index=False)

    return data

def format_result(data):
    return f"""
=== Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ ===
ÙƒÙ„Ù…Ø©: {data.get('Word','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ù…Ø³ØªÙˆÙ‰ CEFR: {data.get('CEFR Level','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ø§Ù„Ù…Ø¬Ø§Ù„: {data.get('Field','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ù†ÙˆØ¹ Ø§Ù„ÙƒÙ„Ù…Ø©: {data.get('Part of Speech','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ø§Ù„Ø¬Ø°Ø±: {data.get('Lemma','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ø§Ù„ØªØ¹Ø±ÙŠÙ: {data.get('Definition','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ø§Ù„Ù…Ø±Ø§Ø¯ÙØ§Øª: {data.get('Synonyms','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯: {data.get('Antonyms','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ù…Ø«Ø§Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…: {data.get('Phrase Example','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ø§Ù„Ø³ÙŠØ§Ù‚: {data.get('Ø§Ù„Ø³ÙŠØ§Ù‚','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
=====================
"""

# -------------------- TELEGRAM HANDLERS --------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Ø³Ù„Ø§Ù…! Ø£Ø±Ø³Ù„ Ù„ÙŠ ÙƒÙ„Ù…Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø´ Ù†Ø­Ù„Ù„Ù‡Ø§ Ù„Ùƒ.")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    word = update.message.text.strip()
    if not ARABIC_REGEX.match(word):
        await update.message.reply_text("âš ï¸ ÙŠÙØ³Ù…Ø­ ÙÙ‚Ø· Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰!")
        return
    data = fetch_word_data(word)
    audio_file = speak(word)
    await update.message.reply_audio(audio=InputFile(audio_file))
    os.remove(audio_file)
    await update.message.reply_text(format_result(data))

# -------------------- MAIN --------------------
if __name__ == "__main__":
    app = ApplicationBuilder().token(TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_message))
    print("ğŸ¤– Bot is running...")
    app.run_polling()



