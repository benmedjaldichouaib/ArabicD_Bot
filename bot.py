import re
import pandas as pd
import google.generativeai as genai
from camel_tools.utils.dediac import dediac_ar
from gtts import gTTS
from telegram import Update, InputFile
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes, MessageHandler, filters
import os

# -------------------- CONFIGURATION --------------------

TOKEN = os.environ.get("TOKEN")
GENIE_API_KEY = os.environ.get("GENIE_API_KEY")
genai.configure(api_key=GENIE_API_KEY)

CSV_FILE = "sorted_cefr.csv" # CSV file in the same folder as bot.py

# -------------------- LOAD CSV --------------------

df = pd.read_csv(CSV_FILE)
df.columns = df.columns.str.strip()

# -------------------- REGEX --------------------

ARABIC_REGEX = re.compile(r'^[\u0600-\u06FF]+$')

# -------------------- FUNCTIONS --------------------

def speak(word, filename="word_output.mp3"):
tts = gTTS(word, lang="ar")
tts.save(filename)
return filename

def normalize_arabic_word(word):
"""Remove diacritics and definite article"""
return dediac_ar(word).lstrip("Ø§Ù„")

def normalize_with_gemini(word):
prompt = f"""
Ø§Ù„ÙƒÙ„Ù…Ø©: "{word}"
Ù‡Ù„ Ø§Ù„ÙƒÙ„Ù…Ø© Ù…Ø¹Ø±ÙØ© Ø¨Ù€ "Ø§Ù„" Ø£Ùˆ Ø¬Ù…Ø¹ØŸ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ÙƒØ°Ù„ÙƒØŒ Ø£Ø¹Ø·Ù†ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ø¨ØµÙŠØºØªÙ‡Ø§ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø£Ùˆ Ø§Ù„Ù…ÙØ±Ø¯Ø© ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø´Ø±Ø­ Ø¥Ø¶Ø§ÙÙŠ.
ÙÙ‚Ø· Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØ±Ø¯Ø© Ø£Ùˆ Ø§Ù„Ø£ØµÙ„ÙŠØ©.
Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙƒÙ„Ù…Ø© Ø£ØµÙ„ÙŠØ© ÙØ¹Ù„Ù‹Ø§ØŒ Ø£Ø¹Ø¯ Ù†ÙØ³ Ø§Ù„ÙƒÙ„Ù…Ø© ÙÙ‚Ø·.
"""
model = genai.GenerativeModel("gemini-2.5-flash")
response = model.generate_content(prompt)
return response.text.strip().split()[0] if response.text else word

def get_gemini_completion(word):
prompt = f"""
Ø£Ø¹Ø·Ù†ÙŠ ØªØ­Ù„ÙŠÙ„Ù‹Ø§ Ø¯Ù‚ÙŠÙ‚Ù‹Ø§ ÙˆÙ…Ù†Ø³Ù‚Ù‹Ø§ Ù„Ù„ÙƒÙ„Ù…Ø© "{word}" Ø¨ØµÙŠØºØ© ÙˆØ§Ø¶Ø­Ø©ØŒ Ø­ÙŠØ« ÙƒÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø© ØªÙƒÙˆÙ† ÙÙŠ Ø³Ø·Ø± Ù…Ø³ØªÙ‚Ù„ ÙˆÙÙ‚Ù‹Ø§ Ù„Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ§Ù„ÙŠ:
ÙƒÙ„Ù…Ø©: {word}
Ù…Ø³ØªÙˆÙ‰ CEFR: (A1, A2, B1, B2, C1, C2 ÙÙ‚Ø·)
Ø§Ù„Ù…Ø¬Ø§Ù„: (Ø­Ø¯Ø¯ Ù…Ø¬Ø§Ù„Ù‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§ ÙÙ‚Ø· Ù…Ø«Ù„: Ù‚Ø§Ù†ÙˆÙ†ØŒ Ø·Ø¨ØŒ Ù‡Ù†Ø¯Ø³Ø©...)
Ù†ÙˆØ¹ Ø§Ù„ÙƒÙ„Ù…Ø©: (Ø§Ø³Ù…ØŒ ÙØ¹Ù„ØŒ ØµÙØ©ØŒ Ø­Ø§Ù„...)
Ø§Ù„Ø¬Ø°Ø±: (Ø§ÙƒØªØ¨ Ø§Ù„Ø¬Ø°Ø± ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø´Ø±Ø­)
Ø§Ù„ØªØ¹Ø±ÙŠÙ: (Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· ØªØ´Ø±Ø­ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø¨ÙˆØ¶ÙˆØ­)
Ø§Ù„Ù…Ø±Ø§Ø¯ÙØ§Øª: (Ù‚Ø§Ø¦Ù…Ø© Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„)
Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯: (Ù‚Ø§Ø¦Ù…Ø© Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„ØŒ Ø£Ùˆ Ø§ÙƒØªØ¨ "ØºÙŠØ± Ù…ØªÙˆÙØ±" Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ)
Ù…Ø«Ø§Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…: (Ø¬Ù…Ù„Ø© Ù‚ØµÙŠØ±Ø© ØªÙˆØ¶Ø­ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒÙ„Ù…Ø©)
Ø§Ù„Ø³ÙŠØ§Ù‚: (ÙˆØ¶Ø­ ÙƒÙŠÙ ØªÙØ³ØªØ®Ø¯Ù… Ø§Ù„ÙƒÙ„Ù…Ø© ÙÙŠ Ø³ÙŠØ§Ù‚ Ù…Ø¹ÙŠÙ†ØŒ Ù…Ø«Ù„: ÙÙŠ Ø§Ù„Ù…Ø¯Ø±Ø³Ø©ØŒ ÙÙŠ Ø§Ù„Ø³ÙˆÙ‚ØŒ ÙÙŠ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ©...)
**Ù…Ù‡Ù…**: Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ø´Ø±Ø­ Ø²Ø§Ø¦Ø¯ Ø®Ø§Ø±Ø¬ Ù‡Ø°Ø§ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚.
"""
model = genai.GenerativeModel("gemini-2.0-flash")
response = model.generate_content(prompt)
return response.text.strip() if response.text else "ØºÙŠØ± Ù…ØªÙˆÙØ±"

def fetch_word_data(word):
global df
base_word = normalize_with_gemini(word)
normalized_word = normalize_arabic_word(base_word)
result = df[df["Word"] == normalized_word]

```
is_new_word = result.empty
data = {}
if not is_new_word:
    data.update(result.iloc[0].to_dict())
else:
    generated_text = get_gemini_completion(normalized_word)
    fields = {
        "CEFR Level": "Ù…Ø³ØªÙˆÙ‰ CEFR",
        "Field": "Ø§Ù„Ù…Ø¬Ø§Ù„",
        "Part of Speech": "Ù†ÙˆØ¹ Ø§Ù„ÙƒÙ„Ù…Ø©",
        "Lemma": "Ø§Ù„Ø¬Ø°Ø±",
        "Definition": "Ø§Ù„ØªØ¹Ø±ÙŠÙ",
        "Synonyms": "Ø§Ù„Ù…Ø±Ø§Ø¯ÙØ§Øª",
        "Antonyms": "Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯",
        "Phrase Example": "Ù…Ø«Ø§Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…",
        "Ø§Ù„Ø³ÙŠØ§Ù‚": "Ø§Ù„Ø³ÙŠØ§Ù‚"
    }
    data["Word"] = normalized_word
    for field, label in fields.items():
        for line in generated_text.split("\n"):
            if line.startswith(label):
                data[field] = line.split(": ", 1)[1] if ": " in line else "ØºÙŠØ± Ù…ØªÙˆÙØ±"
                break
        else:
            data[field] = "ØºÙŠØ± Ù…ØªÙˆÙØ±"
    # Add new word to CSV
    df = pd.concat([df, pd.DataFrame([data])], ignore_index=True)
    df.to_csv(CSV_FILE, index=False)

return data
```

def format_result(data):
return f"""
=== Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ ===
ÙƒÙ„Ù…Ø©: {data.get('Word','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ù…Ø³ØªÙˆÙ‰ CEFR: {data.get('CEFR Level','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ø§Ù„Ù…Ø¬Ø§Ù„: {data.get('Field','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ù†ÙˆØ¹ Ø§Ù„ÙƒÙ„Ù…Ø©: {data.get('Part of Speech','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ø§Ù„Ø¬Ø°Ø±: {data.get('Lemma','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ø§Ù„ØªØ¹Ø±ÙŠÙ: {data.get('Definition','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ø§Ù„Ù…Ø±Ø§Ø¯ÙØ§Øª: {data.get('Synonyms','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ø§Ù„Ø£Ø¶Ø¯Ø§Ø¯: {data.get('Antonyms','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ù…Ø«Ø§Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…: {data.get('Phrase Example','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
Ø§Ù„Ø³ÙŠØ§Ù‚: {data.get('Ø§Ù„Ø³ÙŠØ§Ù‚','ØºÙŠØ± Ù…ØªÙˆÙØ±')}
========================================

"""

# -------------------- TELEGRAM HANDLERS --------------------

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
await update.message.reply_text("Ø³Ù„Ø§Ù…! Ø£Ø±Ø³Ù„ Ù„ÙŠ ÙƒÙ„Ù…Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø´ Ù†Ø­Ù„Ù„Ù‡Ø§ Ù„Ùƒ.")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
word = update.message.text.strip()
if not ARABIC_REGEX.match(word):
await update.message.reply_text("âš ï¸ ÙŠÙØ³Ù…Ø­ ÙÙ‚Ø· Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰!")
return

```
data = fetch_word_data(word)
# Send TTS audio
audio_file = speak(word)
await update.message.reply_audio(audio=InputFile(audio_file))
os.remove(audio_file)  # clean up after sending
# Send text result
await update.message.reply_text(format_result(data))
```

# -------------------- MAIN --------------------

app = ApplicationBuilder().token(TOKEN).build()
app.add_handler(CommandHandler("start", start))
app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_message))
print("ğŸ¤– Bot is running...")
app.run_polling()

